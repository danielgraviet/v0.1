# Phase 1 — Vertical Contract Definition

**Goal:** Define what data flows through Alpha SRE before any code is written. This is the product contract at the schema level — the agreed shapes of every object the system will produce and consume.

> Vision, problem statement, target user, and non-goals are defined in `phase_0.md`. This phase picks up where that left off.

---

## What This Phase Defines

Phase 0 answered: *what are we building and for whom?*

Phase 1 answers: *what does the data look like?*

Specifically:
- What does an **incident** look like to Alpha?
- What is a **signal** (fact vs interpretation)?
- What roles do the **agents** play?
- What is a **hypothesis**?
- What does the final **output** look like?

These definitions constrain everything in Phases 2–4. Get them wrong here and you rebuild half the system later.

---

## Core Concept: Facts vs Interpretations

This is the most important architectural decision in Alpha SRE.

**Signals = Facts.** Extracted deterministically. No LLM involved. Reproducible.

**Hypotheses = Interpretations.** Generated by agents. Probabilistic. Grounded in signals.

Agents never invent signals. They reason over them. If a hypothesis doesn't reference a real signal, the judge rejects it.

This separation is what makes Alpha's output trustworthy — and what separates it from an LLM wrapper.

---

## 1. Incident Input

What does an "incident" look like to Alpha? A structured payload with four data sources:
1. logs
2. metrics
3. recent commits
4. config snapshot

```json
{
  "deployment_id": "deploy-2024-11-15-v2.3.1",
  "logs": ["ERROR timeout...", "ERROR DB pool exhausted..."],
  "metrics": {
    "latency_p99_ms": 4800,
    "latency_baseline_p99_ms": 120,
    "error_rate": 0.31,
    "error_rate_baseline": 0.01,
    "db_connection_pool_used": 5,
    "db_connection_pool_max": 5,
    "cache_hit_rate": 0.08,
    "cache_hit_rate_baseline": 0.82
  },
  "recent_commits": [
    {
      "sha": "a1b2c3d",
      "message": "Refactor user profile endpoint",
      "diff_summary": "Removed @cache decorator. Added SELECT * JOIN query."
    }
  ],
  "config_snapshot": {
    "MAX_DB_CONNECTIONS": 5,
    "CACHE_TTL_SECONDS": 0
  }
}
```

**Data sources — where each field comes from:**

| Field | Source | Status |
|---|---|---|
| `logs` | Sentry (error events, stack traces) | Live integration |
| `metrics` | Sentry (performance monitoring — p99, error rate) | Live integration |
| `recent_commits` | GitHub API (commits in the deploy window) | Deterministic stub |
| `config_snapshot` | GitHub API (config file at deploy SHA) | Deterministic stub |

**GitHub stub strategy:**

For the hackathon, `recent_commits` and `config_snapshot` are returned by a deterministic stub that mirrors exactly what a real GitHub API call would produce. The stub always returns the Incident B payload — it is not random. The interface is identical to what the real integration will use, so swapping stub → live requires changing one line.

```python
class GitHubClient:
    def get_recent_commits(self, repo: str, since: str) -> list[dict]:
        # Stub: returns Incident B commits
        # Real: GET api.github.com/repos/{repo}/commits?since={since}
        return INCIDENT_B_COMMITS

    def get_config_snapshot(self, repo: str, sha: str) -> dict:
        # Stub: returns Incident B config
        # Real: GET api.github.com/repos/{repo}/contents/config.py?ref={sha}
        return INCIDENT_B_CONFIG
```

In the demo: *"We pull recent commits and config state from GitHub."* That is accurate — the stub mirrors the GitHub response format exactly.

**Other scope decisions locked:**
- Alpha does not ingest Prometheus, Datadog, or streaming metrics
- Sentry is the one live integration for errors and performance data
- Baseline values come from Sentry's own baseline tracking, included in the payload
- Commit diffs are summarized strings, not raw patch files

---

## 2. Signals Layer

Signals are extracted deterministically before any agent runs. They are the verified facts of the incident.

**Signal schema:**

```json
{
  "id": "sig_003",
  "type": "resource_saturation",
  "description": "DB connection pool 100% saturated (5/5 used)",
  "value": 1.0,
  "severity": "high",
  "source": "metrics_analyzer"
}
```

**Signal types for Incident B:**

| Type | Produced By | Example |
|---|---|---|
| `log_anomaly` | LogAnalyzer | Error rate 3.1x above baseline |
| `metric_spike` | MetricsAnalyzer | p99 latency 40x above baseline |
| `resource_saturation` | MetricsAnalyzer | DB pool 100% saturated |
| `metric_degradation` | MetricsAnalyzer | Cache hit rate dropped from 82% to 8% |
| `commit_change` | CommitAnalyzer | Cache decorator removed from profile endpoint |
| `config_change` | ConfigAnalyzer | MAX_DB_CONNECTIONS reduced from 20 to 5 |

**Key constraints:**
- Signal IDs are sequential strings assigned by `SignalExtractor` (`sig_001`, `sig_002`, ...)
- Agents receive the signal list, not the raw incident payload
- Signals are immutable once extracted — agents cannot modify them

---

## 3. Agent Team Model

Alpha SRE models a parallel AI SRE team. Five roles, each with a distinct focus:

| Agent | Signal Focus | Model | Role |
|---|---|---|---|
| LogAgent | `log_anomaly` | claude-sonnet-4-6 | Interprets error patterns |
| MetricsAgent | `metric_spike`, `resource_saturation`, `metric_degradation` | gemini-2.0-flash | Interprets resource and performance data |
| CommitAgent | `commit_change` | claude-sonnet-4-6 | Interprets code changes |
| ConfigAgent | `config_change` | gemini-2.0-flash | Interprets environment changes |
| SynthesisAgent | All signals + hypotheses | claude-sonnet-4-6 | Writes the investigation narrative |

**Constraints on agents:**
- Agents do NOT call other agents
- Agents do NOT store state between runs
- Agents do NOT see raw incident data — only the signal list
- The first four agents run in parallel; SynthesisAgent runs after aggregation

---

## 4. Hypothesis Model

Each hypothesis is an independent candidate root cause. Hypotheses are not ranked within an agent — ranking happens in the aggregator.

```json
{
  "label": "DB Connection Pool Exhaustion",
  "description": "Pool reduced to 5 in latest deploy. Unindexed JOIN query causes slow DB ops. Pool saturates at normal load.",
  "confidence": 0.85,
  "severity": "high",
  "supporting_signals": ["sig_003", "sig_006", "sig_007"],
  "contributing_agent": "metrics_agent"
}
```

**Constraints:**
- `confidence` is between 0.0 and 1.0
- `supporting_signals` must contain at least one valid signal ID
- Hypotheses are independent — no causal graphs, no hierarchies
- The judge rejects any hypothesis with empty `supporting_signals`

---

## 5. Aggregated Output

The final output is what the user sees. It answers: *what most likely caused this incident?*

```json
{
  "ranked_hypotheses": [
    {
      "label": "DB Connection Pool Exhaustion",
      "confidence": 0.92,
      "severity": "high",
      "supporting_signals": ["sig_003", "sig_006", "sig_007"],
      "contributing_agents": ["metrics_agent", "commit_agent"]
    }
  ],
  "synthesis": {
    "summary": "Two LLM-assisted commits combined to saturate the DB connection pool...",
    "key_finding": "Cache removal + unindexed query + reduced pool = latency cascade.",
    "confidence_in_ranking": 0.89
  },
  "requires_human_review": true
}
```

**Ranking logic:**
- `final_score = base_confidence + agreement_bonus`
- `agreement_bonus` = +0.1 per additional agent flagging the same root cause
- Deduplication: hypotheses with matching labels are merged; contributing agents are listed

---

## Phase 1 Deliverables

These are decisions, not code. Treat them as the spec that Phases 2–4 build against.

- [X] Incident Input schema defined (fields, types, baseline strategy)
- [X] Data sources mapped (Sentry live, GitHub stub for commits + config)
- [X] Signal schema defined (id, type, description, value, severity, source)
- [X] Signal types enumerated for Incident B
- [X] Agent team model defined (5 roles, model assignments, parallelism rules)
- [X] Hypothesis schema defined (label, confidence, signals, agent)
- [X] Aggregated output schema defined (ranked list, synthesis, human review gate)
- [X] Facts vs interpretations separation locked

---

## What Phase 1 Enables

With these contracts defined:
- Phase 2 knows exactly what `Pydantic` models to write
- Phase 3 knows exactly what `Signal` objects to produce
- Phase 4 knows exactly what `Hypothesis` objects agents must return
- The judge knows exactly what to validate
- The aggregator knows exactly what to rank

No schema ambiguity downstream.
